{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3.2 Artificial Neural Netwoks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial Neural Networks are inspired by the hypothesis that mental activity consists primarily of electromechanical activity in networks of brain cells called neurons. These neurons perform a simple function based on its inputs, and output signals if certain conditions are met. ANN's are an artificial intelligence technique used for visual processing, pattern recognition, and several other tasks. ANN's also have the ability to learn through given examples without any prior knowledge.\n",
    "\n",
    "![neuron](./images/neuron.jpg)\n",
    "\n",
    "ANN's were introduced in the early 1940's as a computational model. They gained a lot of popularity in the early research of AI in the 1980's, and eventually faded due to complexity and lack of computational power for large net systems. However, they have lately started to be re-evaluated and implemented since systems today are much more powerful, and they are being used heavily in some speech recognition systems and visual processors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In neural nets, a single neuron will activate (\"Fire\") when the linear combination of its input exceed some threshold. Below, we can see a simple mathematical model for a neuron:\n",
    "\n",
    "$$a_{j} = g(\\sum_{i=0}^{n} \\omega_{i,j} a_{i})$$\n",
    "\n",
    "where $a_{i}$ = The Output activation of unit i and $\\omega_{i,j}$ is the weight on a link from unit i to this unit. The below image is a graphical representation of this model.\n",
    "\n",
    "![mathModel](./images/model.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component for neural nets is the neuron. A Neuron labelled *j* receives input $P_{j}(t)$ from predecessor neurons. These neurons consist of the following:\n",
    "\n",
    ">  \n",
    "1. Activation $a_{j}(t)$ depending on a discrete time parameter  \n",
    "2. Threshold $\\theta_{j}$ that stays fixed unless changed by a learning function  \n",
    "3. Activation Function *f* that computesthe new activation at a given time $t+1$ from $a_{j}(t),\\theta_{t}$ and the net input $P_{j}(t)$ that gives rise to the relation $a_{j}(t+1)=f(a_{j}(t),P_{j}(t),\\theta_{j})$  \n",
    "4. Output function computing the outputfrom the activation $O_{j} = f_{out}(a_{j}(t))$\n",
    "\n",
    "The second component of neural nets are the connections and weights. The network consists of connections where each connection transfers the output of a neuron *i* to the input of a neuron *j*. Each connection is assigned a weight $\\omega_{i,j}$\n",
    "\n",
    "The third component of neural nets are the propogation functions. This function computes the input of $P_{j}(t)$ to neuron *j* from outputs $O_{i}(t)$ where:\n",
    "\n",
    "$$P_{j}(t) = \\sum_{i} O_{i}(t) \\omega_{i,j}$$\n",
    "\n",
    "Lastly, neural nets consist of a learning rule. This is either a rule or algorithm that modifies the parameters of a neural net in order for a given input to the network to produce a forward output. The learning process typically simple modifies the weights and thresholds of the variables within the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function of a neron is typically a hard threshold called a perceptron or a logistic function called a sigmoid perceptron. Both functions ensure the property that the entire network of units can represent a non-linear function. The sigmoid perceptron also has some advantages such as a garunteed number between 0 and 1 and has the ability to be differentiable.\n",
    "\n",
    "There are two types of connections used in neural nets. These are the Feed-Forward networks and the Recurrent networks. Recurrent networks have a tendancy to be quite chaotic, but because these networks feed backwards into the net, short term memory is possible. Feed-Forward networks are normally arranged in layers. In a multi-layered Feed-Forward net, the layers that are located between the input layer and the output layer are known as hidden layers. Below is a graphic showing this in a 3 layered net.\n",
    "\n",
    "![Layered](./images/hiddenLayer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we will introduce a single learning technique known as Back Propogation. Back Propogation can be implemented as supervised learning, unsupervised learning, or as reinforcement learning. We will be using supervised learning in this lesson. Supervised learning is where the user can control the learning of the AI method. This is acheived by control of the given examples, and ultimate control over the outcomes.\n",
    "\n",
    "Back propogation learning is acheived in 2 main steps:\n",
    "\n",
    ">  \n",
    "1. Compute the $\\Delta$ values for the output units using the observed error.  \n",
    "2. Starting with the output layer, repeat the following steps for each layer in the net until the earliest hidden layer has been is reached:\n",
    "\n",
    ">>  \n",
    "A. Propogate the $\\Delta$ values back to the previous layer  \n",
    "B. Update the weights between the 2 layers  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Graphic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graphic displays the effects of the obove. This example was created for recognizing hand-written numbers in an image. The start of the net has 1 input for each individual pixel. Then, it has 2 hidden layers that ultimately recognizize pieces of an image and the sends those signals to the output layer. After the output layer, an answer is chosen based on highest probable output.\n",
    "\n",
    "![graphic](./images/NeuralNets.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
